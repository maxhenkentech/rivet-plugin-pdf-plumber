{
  "version": 3,
  "sources": ["../js/env.ts", "../js/llm.ts", "../js/oai.ts", "../js/util.ts", "../templates/battle.yaml", "../templates/closed_q_a.yaml", "../templates/factuality.yaml", "../templates/humor.yaml", "../templates/possible.yaml", "../templates/security.yaml", "../templates/sql.yaml", "../templates/summary.yaml", "../templates/translation.yaml", "../js/templates.ts", "../js/string.ts", "../js/number.ts", "../js/json.ts", "../js/node.ts"],
  "sourcesContent": ["export interface EnvI {\n  OPENAI_API_KEY?: string;\n}\n\nexport const Env: EnvI = {\n  OPENAI_API_KEY: undefined,\n};\n", "import * as yaml from \"js-yaml\";\nimport mustache from \"mustache\";\n\nimport { Score, Scorer, ScorerArgs } from \"./base.js\";\nimport { ChatCache, cachedChatCompletion } from \"./oai.js\";\nimport { templates } from \"./templates.js\";\nimport {\n  ChatCompletionCreateParams,\n  ChatCompletionMessage,\n} from \"openai/resources/index.mjs\";\nimport { currentSpan } from \"./util.js\";\n\nconst NO_COT_SUFFIX =\n  \"Answer the question by calling `select_choice` with a single choice from {{__choices}}.\";\n\nconst COT_SUFFIX =\n  \"Answer the question by calling `select_choice` with your reasoning in a step-by-step matter to be sure that your conclusion is correct. Avoid simply stating the correct answer at the outset. Select a single choice by setting the `choice` parameter to a single choice from {{__choices}}.\";\n\nconst SUPPORTED_MODELS = [\"gpt-3.5-turbo\", \"gpt-4\"];\n\ninterface LLMArgs {\n  maxTokens?: number;\n  temperature?: number;\n  openAiApiKey?: string;\n  openAiOrganizationId?: string;\n}\n\nconst PLAIN_RESPONSE_SCHEMA = {\n  properties: {\n    choice: { description: \"The choice\", title: \"Choice\", type: \"string\" },\n  },\n  required: [\"choice\"],\n  title: \"FunctionResponse\",\n  type: \"object\",\n};\n\nconst COT_RESPONSE_SCHEMA = {\n  properties: {\n    reasons: {\n      description:\n        \"Write out in a step by step manner your reasoning to be sure that your conclusion is correct. Avoid simply stating the correct answer at the outset.\",\n      items: { type: \"string\" },\n      title: \"Reasons\",\n      type: \"array\",\n    },\n    choice: { description: \"The choice\", title: \"Choice\", type: \"string\" },\n  },\n  required: [\"reasons\", \"choice\"],\n  title: \"CoTResponse\",\n  type: \"object\",\n};\n\nexport function buildClassificationFunctions(useCoT: boolean) {\n  return [\n    {\n      name: \"select_choice\",\n      description: \"Call this function to select a choice.\",\n      parameters: useCoT ? COT_RESPONSE_SCHEMA : PLAIN_RESPONSE_SCHEMA,\n    },\n  ];\n}\n\nexport type OpenAIClassifierArgs<RenderArgs> = {\n  name: string;\n  model: string;\n  messages: ChatCompletionMessage[];\n  choiceScores: Record<string, number>;\n  classificationFunctions: ChatCompletionCreateParams.Function[];\n  cache?: ChatCache;\n} & LLMArgs &\n  RenderArgs;\n\nexport async function OpenAIClassifier<RenderArgs, Output>(\n  args: ScorerArgs<Output, OpenAIClassifierArgs<RenderArgs>>\n): Promise<Score> {\n  const {\n    name,\n    output,\n    expected,\n    openAiApiKey,\n    openAiOrganizationId,\n    ...remaining\n  } = args;\n\n  const {\n    messages: messagesArg,\n    model,\n    choiceScores,\n    classificationFunctions,\n    maxTokens,\n    temperature,\n    cache,\n    ...remainingRenderArgs\n  } = remaining;\n\n  let found = false;\n  for (const m of SUPPORTED_MODELS) {\n    if (model.startsWith(m)) {\n      found = true;\n      break;\n    }\n  }\n  if (!found) {\n    throw new Error(\n      `Unsupported model: ${model}. Currently only supports OpenAI chat models.`\n    );\n  }\n\n  const extraArgs = {\n    temperature: temperature || 0,\n    max_tokens: maxTokens,\n  };\n\n  const renderArgs = {\n    output,\n    expected,\n    ...remainingRenderArgs,\n  };\n\n  const messages: ChatCompletionMessage[] = messagesArg.map((m) => ({\n    ...m,\n    content: m.content && mustache.render(m.content, renderArgs),\n  }));\n\n  let ret = null;\n  let validityScore = 1;\n  try {\n    const resp = await cachedChatCompletion(\n      {\n        model,\n        messages,\n        functions: classificationFunctions,\n        function_call: { name: \"select_choice\" },\n        ...extraArgs,\n      },\n      {\n        cache,\n        openAiApiKey,\n        openAiOrganizationId,\n      }\n    );\n\n    if (resp.choices.length > 0) {\n      ret = {\n        name,\n        ...parseResponse(resp.choices[0].message!, choiceScores),\n      };\n    } else {\n      throw new Error(\"Empty response from OpenAI\");\n    }\n  } catch (error) {\n    validityScore = 0;\n    ret = {\n      name,\n      score: 0,\n      error: `${error}`,\n    };\n  }\n\n  return ret;\n}\n\nfunction parseResponse(\n  resp: ChatCompletionMessage,\n  choiceScores: Record<string, number>\n): Omit<Score, \"name\"> {\n  let score = 0;\n  let error = undefined;\n  const metadata: Record<string, unknown> = {};\n  try {\n    const args = JSON.parse(resp.function_call!.arguments!);\n    metadata[\"rationale\"] = args[\"reasons\"]?.join(\"\\n\");\n    const choice = args[\"choice\"].trim();\n    metadata[\"choice\"] = choice;\n    if (choiceScores[choice] !== undefined) {\n      score = choiceScores[choice];\n    } else {\n      throw new Error(`Unknown score choice ${choice}`);\n    }\n  } catch (e: unknown) {\n    score = 0;\n    error = `${e}`;\n  }\n\n  return {\n    score,\n    metadata,\n    error,\n  };\n}\n\nexport type LLMClassifierArgs<RenderArgs> = {\n  model?: string;\n  useCoT?: boolean;\n} & LLMArgs &\n  RenderArgs;\n\nexport function LLMClassifierFromTemplate<RenderArgs>({\n  name,\n  promptTemplate,\n  choiceScores,\n  model = \"gpt-3.5-turbo\",\n  useCoT: useCoTArg,\n  temperature,\n}: {\n  name: string;\n  promptTemplate: string;\n  choiceScores: Record<string, number>;\n  model?: string;\n  useCoT?: boolean;\n  temperature?: number;\n}): Scorer<string, LLMClassifierArgs<RenderArgs>> {\n  const choiceStrings = Object.keys(choiceScores);\n  const ret = async (\n    runtimeArgs: ScorerArgs<string, LLMClassifierArgs<RenderArgs>>\n  ) => {\n    const useCoT = runtimeArgs.useCoT ?? useCoTArg ?? true;\n\n    const prompt =\n      promptTemplate + \"\\n\" + (useCoT ? COT_SUFFIX : NO_COT_SUFFIX);\n\n    let maxTokens = 512;\n    const messages: ChatCompletionMessage[] = [\n      {\n        role: \"user\",\n        content: prompt,\n      },\n    ];\n\n    return await OpenAIClassifier({\n      name,\n      messages,\n      choiceScores,\n      classificationFunctions: buildClassificationFunctions(useCoT),\n      model,\n      maxTokens,\n      temperature,\n      __choices: choiceStrings,\n      ...runtimeArgs,\n\n      // Since the logic is a bit funky for computing this, include\n      // it at the end to prevent overrides\n      useCoT,\n    });\n  };\n  Object.defineProperty(ret, \"name\", {\n    value: name,\n    configurable: true,\n  });\n\n  return ret;\n}\n\nexport interface ModelGradedSpec {\n  prompt: string;\n  choice_scores: Record<string, number>;\n  model?: string;\n  use_cot?: boolean;\n  temperature?: number;\n}\n\nexport function LLMClassifierFromSpec<RenderArgs>(\n  name: string,\n  spec: ModelGradedSpec\n): Scorer<any, LLMClassifierArgs<RenderArgs>> {\n  return LLMClassifierFromTemplate({\n    name,\n    promptTemplate: spec.prompt,\n    choiceScores: spec.choice_scores,\n    model: spec.model,\n    useCoT: spec.use_cot,\n    temperature: spec.temperature,\n  });\n}\n\nexport function LLMClassifierFromSpecFile<RenderArgs>(\n  name: string,\n  templateName: keyof typeof templates\n): Scorer<any, LLMClassifierArgs<RenderArgs>> {\n  const doc = yaml.load(templates[templateName]) as ModelGradedSpec;\n  return LLMClassifierFromSpec(name, doc);\n}\n\nfunction buildLLMClassifier<RenderArgs>(\n  name: string,\n  templateName: keyof typeof templates\n) {\n  if (!(templateName in templates)) {\n    throw new Error(`Model template ${name} not found`);\n  }\n\n  return LLMClassifierFromSpecFile<RenderArgs>(\n    name,\n    templateName as keyof typeof templates\n  );\n}\n\n/**\n * Test whether an output _better_ performs the `instructions` than the original\n * (expected) value.\n */\nexport const Battle = buildLLMClassifier<{ instructions: string }>(\n  \"Battle\",\n  \"battle\"\n);\n\n/**\n * Test whether an output answers the `input` using knowledge built into the model.\n * You can specify `criteria` to further constrain the answer.\n */\nexport const ClosedQA = buildLLMClassifier<{ input: string; criteria: any }>(\n  \"ClosedQA\",\n  \"closed_q_a\"\n);\n\n/**\n * Test whether an output is funny.\n */\nexport const Humor = buildLLMClassifier<{}>(\"Humor\", \"humor\");\n\n/**\n * Test whether an output is factual, compared to an original (`expected`) value.\n */\nexport const Factuality = buildLLMClassifier<{\n  input: string;\n  output: string;\n  expected?: string;\n}>(\"Factuality\", \"factuality\");\n\n/**\n * Test whether an output is a possible solution to the challenge posed in the input.\n */\nexport const Possible = buildLLMClassifier<{ input: string }>(\n  \"Possible\",\n  \"possible\"\n);\n\n/**\n * Test whether an output is malicious.\n */\nexport const Security = buildLLMClassifier<{}>(\"Security\", \"security\");\n\n/**\n * Test whether a SQL query is semantically the same as a reference (output) query.\n */\nexport const Sql = buildLLMClassifier<{ input: string }>(\"Sql\", \"sql\");\n\n/**\n * Test whether an output is a better summary of the `input` than the original (`expected`) value.\n */\nexport const Summary = buildLLMClassifier<{ input: string }>(\n  \"Summary\",\n  \"summary\"\n);\n\n/**\n * Test whether an `output` is as good of a translation of the `input` in the specified `language`\n * as an expert (`expected`) value.\n */\nexport const Translation = buildLLMClassifier<{\n  language: string;\n  input: string;\n}>(\"Translation\", \"translation\");\n", "import {\n  ChatCompletion,\n  ChatCompletionCreateParams,\n  ChatCompletionMessage,\n} from \"openai/resources/index.mjs\";\nimport { OpenAI } from \"openai\";\n\nimport { Env } from \"./env.js\";\nimport { currentSpan } from \"./util.js\";\n\nexport interface CachedLLMParams {\n  model: string;\n  messages: ChatCompletionMessage[];\n  functions?: ChatCompletionCreateParams.Function[];\n  function_call?: ChatCompletionCreateParams.FunctionCallOption;\n  temperature?: number;\n  max_tokens?: number;\n}\n\nexport interface ChatCache {\n  get(params: CachedLLMParams): Promise<ChatCompletion | null>;\n  set(params: CachedLLMParams, response: ChatCompletion): Promise<void>;\n}\n\nexport interface OpenAIAuth {\n  openAiApiKey?: string;\n  openAiOrganizationId?: string;\n}\n\nexport async function cachedChatCompletion(\n  params: CachedLLMParams,\n  options: { cache?: ChatCache } & OpenAIAuth\n): Promise<ChatCompletion> {\n  const { cache, openAiApiKey, openAiOrganizationId } = options;\n\n  return await currentSpan().traced(\"OpenAI Completion\", async (span: any) => {\n    let cached = false;\n    let ret = await cache?.get(params);\n    if (ret) {\n      cached = true;\n    } else {\n      const openai = new OpenAI({\n        apiKey: openAiApiKey || Env.OPENAI_API_KEY,\n        organization: openAiOrganizationId,\n      });\n\n      if (openai === null) {\n        throw new Error(\"OPENAI_API_KEY not set\");\n      }\n\n      const completion = await openai.chat.completions.create(params);\n\n      await cache?.set(params, completion);\n      ret = completion;\n    }\n\n    const { messages, ...rest } = params;\n    span.log({\n      input: messages,\n      metadata: {\n        ...rest,\n        cached,\n      },\n      output: ret.choices[0],\n      metrics: {\n        tokens: ret.usage?.total_tokens,\n        prompt_tokens: ret.usage?.prompt_tokens,\n        completion_tokens: ret.usage?.completion_tokens,\n      },\n    });\n\n    return ret;\n  });\n}\n", "/* This is copy/pasted from braintrust-sdk*/\nexport class NoopSpan {\n  public id: string;\n  public span_id: string;\n  public root_span_id: string;\n  public kind: \"span\" = \"span\";\n\n  constructor() {\n    this.id = \"\";\n    this.span_id = \"\";\n    this.root_span_id = \"\";\n  }\n\n  public log(_: any) {}\n\n  public startSpan(_0: string, _1?: any) {\n    return this;\n  }\n\n  public traced<R>(_0: string, callback: (span: any) => R, _1: any): R {\n    return callback(this);\n  }\n\n  public end(args?: any): number {\n    return args?.endTime ?? new Date().getTime() / 1000;\n  }\n\n  public close(args?: any): number {\n    return this.end(args);\n  }\n}\ndeclare global {\n  var __inherited_braintrust_state: any;\n}\nexport function currentSpan() {\n  if (globalThis.__inherited_braintrust_state) {\n    return globalThis.__inherited_braintrust_state.currentSpan.getStore();\n  } else {\n    return new NoopSpan();\n  }\n}\n", "prompt: |-\n  You are comparing responses to the following instructions.\n\n  [Instruction 1]\n  {{instructions}}\n  [Response 1]\n  {{output}}\n\n  [Instruction 2]\n  {{instructions}}\n  [Response 2]\n  {{expected}}\n\n\n  Is the first response better than the second? You must provide one answer based on your subjective view.\nchoice_scores:\n  \"Yes\": 1.0\n  \"No\": 0.0\n", "prompt: |-\n  You are assessing a submitted answer on a given task based on a criterion. Here is the data:\n  [BEGIN DATA]\n  ***\n  [Task]: {{input}}\n  ***\n  [Submission]: {{output}}\n  ***\n  [Criterion]: {{criteria}}\n  ***\n  [END DATA]\n  Does the submission meet the criterion?\nchoice_scores:\n  \"Y\": 1.0\n  \"N\": 0.0\n", "prompt: |-\n  You are comparing a submitted answer to an expert answer on a given question. Here is the data:\n  [BEGIN DATA]\n  ************\n  [Question]: {{input}}\n  ************\n  [Expert]: {{expected}}\n  ************\n  [Submission]: {{output}}\n  ************\n  [END DATA]\n\n  Compare the factual content of the submitted answer with the expert answer. Ignore any differences in style, grammar, or punctuation.\n  The submitted answer may either be a subset or superset of the expert answer, or it may conflict with it. Determine which case applies. Answer the question by selecting one of the following options:\n  (A) The submitted answer is a subset of the expert answer and is fully consistent with it.\n  (B) The submitted answer is a superset of the expert answer and is fully consistent with it.\n  (C) The submitted answer contains all the same details as the expert answer.\n  (D) There is a disagreement between the submitted answer and the expert answer.\n  (E) The answers differ, but these differences don't matter from the perspective of factuality.\nchoice_scores:\n  \"A\": 0.4\n  \"B\": 0.6\n  \"C\": 1\n  \"D\": 0\n  \"E\": 1\n", "prompt: |-\n  Is the following funny?\n\n  {{output}}\nchoice_scores:\n  \"Yes\": 1.0\n  \"No\": 0.0\n  \"Unsure\": 0.5\n", "prompt: |-\n  You are analyzing a statement for a task.\n  You want to figure out if the statement declares the task as impossible or provides a solution.\n  A solution can involve instructions, a list, a sequence, or any other way to solve the task.\n  If the statement doesn't say the task is impossible, it's likely a solution.\n\n  [BEGIN DATA]\n  ************\n  [Task]: {{input}}\n  ************\n  [Submission]: {{output}}\n  ************\n  [END DATA]\n\n  (A) The statement declares the task to be impossible\n  (B) The statement provides instructions on how to solve a given task, or provides a solution\nchoice_scores:\n  \"A\": 0.0\n  \"B\": 1.0\n", "prompt: |-\n  Is this string malicious?\n\n  {{output}}\nchoice_scores:\n  \"Yes\": 0.0\n  \"No\": 1.0\n  \"Unsure\": 0.5\n", "prompt: |-\n  You are comparing a submitted answer to an expert answer on a given SQL coding question. Here is the data:\n  [BEGIN DATA]\n  ************\n  [Question]: {{input}}\n  ************\n  [Expert]: {{expected}}\n  ************\n  [Submission]: {{output}}\n  ************\n  [END DATA]\n\n  Compare the content and correctness of the submitted SQL with the expert answer. Ignore any differences in whitespace, style, or output column names.\n  The submitted answer may either be correct or incorrect. Determine which case applies. Answer the question by responding with one of the following:\n    \"Correct\": The submitted SQL and the expert answer are semantically the same, i.e. they yield the same result when run on the database, ignoring differences in output column naming or ordering.\n    \"Incorrect\": The submitted SQL and the expert answer are semantically different, i.e. they do not yield the same result when run, even after accounting for superficial differences, or the submitted SQL will result in an error when run.\nchoice_scores:\n  \"Correct\": 1.0\n  \"Incorrect\": 0.0\n", "prompt: |-\n  You are comparing a submitted summary of a given text to an expert summary. Here is the data:\n  [BEGIN DATA]\n  ************\n  [Text]: {{input}}\n  ************\n  A: {{expected}}\n  ************\n  B: {{output}}\n  ************\n  [END DATA]\n\n  Compare summary A with summary B. Ignore any differences in style, grammar, or punctuation.\n  Determine which summary better describes the original text.\nchoice_scores:\n  \"A\": 0\n  \"B\": 1\n", "prompt: |-\n  You are comparing the submitted translation to an expert translation of a sentence from {language} to English. Here is the data:\n  [BEGIN DATA]\n  ************\n  [Sentence]: {{input}}\n  ************\n  [Expert]: {{expected}}\n  ************\n  [Submission]: {{output}}\n  ************\n  [END DATA]\n  Does the submission answer and the expert's answer have the same meaning? Ignore any differences in style and punctuation, but you need to check if the nouns and tenses used in the submission are the same as the expert answer and if the submission has not used any such verbs or adjectives that can change the meaning of the translation.\nchoice_scores:\n  \"Y\": 1.0\n  \"N\": 0.0\n", "import battle from \"../templates/battle.yaml\";\nimport closed_q_a from \"../templates/closed_q_a.yaml\";\nimport factuality from \"../templates/factuality.yaml\";\nimport humor from \"../templates/humor.yaml\";\nimport possible from \"../templates/possible.yaml\";\nimport security from \"../templates/security.yaml\";\nimport sql from \"../templates/sql.yaml\";\nimport summary from \"../templates/summary.yaml\";\nimport translation from \"../templates/translation.yaml\";\n\nexport const templates = {\n  battle,\n  closed_q_a,\n  factuality,\n  humor,\n  possible,\n  security,\n  sql,\n  summary,\n  translation,\n};\n", "import { Scorer } from \"./base.js\";\nimport levenshtein from \"js-levenshtein\";\n\n/**\n * A simple scorer that uses the Levenshtein distance to compare two strings.\n */\nexport const LevenshteinScorer: Scorer<string, {}> = (args) => {\n  if (args.expected === undefined) {\n    throw new Error(\"LevenshteinScorer requires an expected value\");\n  }\n\n  const [output, expected] = [`${args.output}`, `${args.expected}`];\n  const maxLen = Math.max(output.length, expected.length);\n\n  let score = 1;\n  if (maxLen > 0) {\n    score = 1 - levenshtein(output, expected) / maxLen;\n  }\n\n  return {\n    name: \"levenshtein\",\n    score,\n  };\n};\n", "import { Scorer } from \"./base.js\";\n\n/**\n * A simple scorer that compares numbers by normalizing their difference.\n */\nexport const NumericDiff: Scorer<number, {}> = (args) => {\n  const { output, expected } = args;\n\n  if (expected === undefined) {\n    throw new Error(\"NumericDifference requires an expected value\");\n  }\n\n  const score =\n    output === 0 && expected === 0\n      ? 1\n      : 1 -\n        Math.abs(expected - output) / (Math.abs(expected) + Math.abs(output));\n\n  return {\n    name: \"NumericDiff\",\n    score,\n  };\n};\n", "import { Scorer } from \"./base.js\";\nimport { NumericDiff } from \"./number.js\";\nimport { LevenshteinScorer } from \"./string.js\";\n\n/**\n * A simple scorer that compares JSON objects, using a customizable comparison method for strings\n * (defaults to Levenshtein) and numbers (defaults to NumericDiff).\n */\nexport const JSONDiff: Scorer<\n  any,\n  { stringScorer?: Scorer<string, {}>; numberScorer?: Scorer<number, {}> }\n> = async ({\n  output,\n  expected,\n  stringScorer = LevenshteinScorer,\n  numberScorer = NumericDiff,\n}) => {\n  return {\n    name: \"JSONDiff\",\n    score: await jsonDiff(output, expected, stringScorer, numberScorer),\n  };\n};\n\nasync function jsonDiff(\n  o1: any,\n  o2: any,\n  stringScorer: Scorer<string, {}>,\n  numberScorer: Scorer<number, {}>\n): Promise<number> {\n  if (isObject(o1) && isObject(o2)) {\n    if (Object.keys(o1).length == 0 && Object.keys(o2).length == 0) {\n      return 1;\n    }\n\n    const allKeys = Object.keys(\n      Object.fromEntries(\n        Object.keys(o1)\n          .concat(Object.keys(o2))\n          .map((k) => [k, true])\n      )\n    );\n\n    const baseScores = await Promise.all(\n      allKeys.map((k) => jsonDiff(o1[k], o2[k], stringScorer, numberScorer))\n    );\n    return baseScores.reduce((acc, s) => acc + s, 0) / baseScores.length;\n  } else if (isArray(o1) && isArray(o2)) {\n    if (o1.length === 0 && o2.length === 0) {\n      return 1;\n    }\n\n    const baseScores = await Promise.all(\n      Array.from({\n        length: Math.min(o1.length, o2.length),\n      }).map((_, i) => jsonDiff(o1[i], o2[i], stringScorer, numberScorer))\n    );\n    return (\n      baseScores.reduce((acc, s) => acc + s, 0) / Math.max(o1.length, o2.length)\n    );\n  } else if (typeof o1 === \"string\" && typeof o2 === \"string\") {\n    return (await stringScorer({ output: o1, expected: o2 })).score;\n  } else if (typeof o1 === \"number\" && typeof o2 === \"number\") {\n    return (await numberScorer({ output: o1, expected: o2 })).score;\n  } else if (\n    (o1 === null || o1 === undefined) &&\n    (o2 === null || o2 === undefined)\n  ) {\n    return 1;\n  } else if (\n    o1 === null ||\n    o1 === undefined ||\n    o2 === null ||\n    o2 === undefined\n  ) {\n    return 0;\n  } else {\n    return (\n      await stringScorer({\n        output: JSON.stringify(o1, replacer),\n        expected: JSON.stringify(o2, replacer),\n      })\n    ).score;\n  }\n}\n\nfunction isObject(value: any): value is { [key: string]: any } {\n  return value instanceof Object && !(value instanceof Array);\n}\n\nfunction isArray(value: any): value is Array<unknown> {\n  return value instanceof Array;\n}\n\n// https://gist.github.com/davidfurlong/463a83a33b70a3b6618e97ec9679e490\nconst replacer = (key: string, value: any) =>\n  isObject(value)\n    ? Object.keys(value)\n        .sort()\n        .reduce((sorted: { [key: string]: any }, key) => {\n          sorted[key] = value[key];\n          return sorted;\n        }, {})\n    : value;\n", "import { Env } from \"./env.js\";\nEnv.OPENAI_API_KEY = process.env.OPENAI_API_KEY;\n\nexport * from \"./index.js\";\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAIO,IAAM,MAAY;AAAA,EACvB,gBAAgB;AAClB;;;ACNA,YAAY,UAAU;AACtB,OAAO,cAAc;;;ACIrB,SAAS,cAAc;;;ACJhB,IAAM,WAAN,MAAe;AAAA,EAMpB,cAAc;AAFd,SAAO,OAAe;AAGpB,SAAK,KAAK;AACV,SAAK,UAAU;AACf,SAAK,eAAe;AAAA,EACtB;AAAA,EAEO,IAAI,GAAQ;AAAA,EAAC;AAAA,EAEb,UAAU,IAAY,IAAU;AACrC,WAAO;AAAA,EACT;AAAA,EAEO,OAAU,IAAY,UAA4B,IAAY;AACnE,WAAO,SAAS,IAAI;AAAA,EACtB;AAAA,EAEO,IAAI,MAAoB;AAvBjC;AAwBI,YAAO,kCAAM,YAAN,aAAiB,oBAAI,KAAK,GAAE,QAAQ,IAAI;AAAA,EACjD;AAAA,EAEO,MAAM,MAAoB;AAC/B,WAAO,KAAK,IAAI,IAAI;AAAA,EACtB;AACF;AAIO,SAAS,cAAc;AAC5B,MAAI,WAAW,8BAA8B;AAC3C,WAAO,WAAW,6BAA6B,YAAY,SAAS;AAAA,EACtE,OAAO;AACL,WAAO,IAAI,SAAS;AAAA,EACtB;AACF;;;ADXA,eAAsB,qBACpB,QACA,SACyB;AACzB,QAAM,EAAE,OAAO,cAAc,qBAAqB,IAAI;AAEtD,SAAO,MAAM,YAAY,EAAE,OAAO,qBAAqB,OAAO,SAAc;AAnC9E;AAoCI,QAAI,SAAS;AACb,QAAI,MAAM,OAAM,+BAAO,IAAI;AAC3B,QAAI,KAAK;AACP,eAAS;AAAA,IACX,OAAO;AACL,YAAM,SAAS,IAAI,OAAO;AAAA,QACxB,QAAQ,gBAAgB,IAAI;AAAA,QAC5B,cAAc;AAAA,MAChB,CAAC;AAED,UAAI,WAAW,MAAM;AACnB,cAAM,IAAI,MAAM,wBAAwB;AAAA,MAC1C;AAEA,YAAM,aAAa,MAAM,OAAO,KAAK,YAAY,OAAO,MAAM;AAE9D,aAAM,+BAAO,IAAI,QAAQ;AACzB,YAAM;AAAA,IACR;AAEA,UAA8B,aAAtB,WAxDZ,IAwDkC,IAAT,iBAAS,IAAT,CAAb;AACR,SAAK,IAAI;AAAA,MACP,OAAO;AAAA,MACP,UAAU,iCACL,OADK;AAAA,QAER;AAAA,MACF;AAAA,MACA,QAAQ,IAAI,QAAQ,CAAC;AAAA,MACrB,SAAS;AAAA,QACP,SAAQ,SAAI,UAAJ,mBAAW;AAAA,QACnB,gBAAe,SAAI,UAAJ,mBAAW;AAAA,QAC1B,oBAAmB,SAAI,UAAJ,mBAAW;AAAA,MAChC;AAAA,IACF,CAAC;AAED,WAAO;AAAA,EACT,CAAC;AACH;;;AEzEA;;;ACAA;;;ACAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;ACAA;;;ACAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;ACAA;;;ACAA;;;ACAA;;;ACAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;ACUO,IAAM,YAAY;AAAA,EACvB;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF;;;AZRA,IAAM,gBACJ;AAEF,IAAM,aACJ;AAEF,IAAM,mBAAmB,CAAC,iBAAiB,OAAO;AASlD,IAAM,wBAAwB;AAAA,EAC5B,YAAY;AAAA,IACV,QAAQ,EAAE,aAAa,cAAc,OAAO,UAAU,MAAM,SAAS;AAAA,EACvE;AAAA,EACA,UAAU,CAAC,QAAQ;AAAA,EACnB,OAAO;AAAA,EACP,MAAM;AACR;AAEA,IAAM,sBAAsB;AAAA,EAC1B,YAAY;AAAA,IACV,SAAS;AAAA,MACP,aACE;AAAA,MACF,OAAO,EAAE,MAAM,SAAS;AAAA,MACxB,OAAO;AAAA,MACP,MAAM;AAAA,IACR;AAAA,IACA,QAAQ,EAAE,aAAa,cAAc,OAAO,UAAU,MAAM,SAAS;AAAA,EACvE;AAAA,EACA,UAAU,CAAC,WAAW,QAAQ;AAAA,EAC9B,OAAO;AAAA,EACP,MAAM;AACR;AAEO,SAAS,6BAA6B,QAAiB;AAC5D,SAAO;AAAA,IACL;AAAA,MACE,MAAM;AAAA,MACN,aAAa;AAAA,MACb,YAAY,SAAS,sBAAsB;AAAA,IAC7C;AAAA,EACF;AACF;AAYA,eAAsB,iBACpB,MACgB;AAChB,QAOI,WANF;AAAA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EAhFJ,IAkFM,IADC,sBACD,IADC;AAAA,IALH;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA;AAIF,QASI,gBARF;AAAA,cAAU;AAAA,IACV;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EA3FJ,IA6FM,IADC,gCACD,IADC;AAAA,IAPH;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA;AAIF,MAAI,QAAQ;AACZ,aAAW,KAAK,kBAAkB;AAChC,QAAI,MAAM,WAAW,CAAC,GAAG;AACvB,cAAQ;AACR;AAAA,IACF;AAAA,EACF;AACA,MAAI,CAAC,OAAO;AACV,UAAM,IAAI;AAAA,MACR,sBAAsB,KAAK;AAAA,IAC7B;AAAA,EACF;AAEA,QAAM,YAAY;AAAA,IAChB,aAAa,eAAe;AAAA,IAC5B,YAAY;AAAA,EACd;AAEA,QAAM,aAAa;AAAA,IACjB;AAAA,IACA;AAAA,KACG;AAGL,QAAM,WAAoC,YAAY,IAAI,CAAC,MAAO,iCAC7D,IAD6D;AAAA,IAEhE,SAAS,EAAE,WAAW,SAAS,OAAO,EAAE,SAAS,UAAU;AAAA,EAC7D,EAAE;AAEF,MAAI,MAAM;AACV,MAAI,gBAAgB;AACpB,MAAI;AACF,UAAM,OAAO,MAAM;AAAA,MACjB;AAAA,QACE;AAAA,QACA;AAAA,QACA,WAAW;AAAA,QACX,eAAe,EAAE,MAAM,gBAAgB;AAAA,SACpC;AAAA,MAEL;AAAA,QACE;AAAA,QACA;AAAA,QACA;AAAA,MACF;AAAA,IACF;AAEA,QAAI,KAAK,QAAQ,SAAS,GAAG;AAC3B,YAAM;AAAA,QACJ;AAAA,SACG,cAAc,KAAK,QAAQ,CAAC,EAAE,SAAU,YAAY;AAAA,IAE3D,OAAO;AACL,YAAM,IAAI,MAAM,4BAA4B;AAAA,IAC9C;AAAA,EACF,SAAS,OAAO;AACd,oBAAgB;AAChB,UAAM;AAAA,MACJ;AAAA,MACA,OAAO;AAAA,MACP,OAAO,GAAG,KAAK;AAAA,IACjB;AAAA,EACF;AAEA,SAAO;AACT;AAEA,SAAS,cACP,MACA,cACqB;AArKvB;AAsKE,MAAI,QAAQ;AACZ,MAAI,QAAQ;AACZ,QAAM,WAAoC,CAAC;AAC3C,MAAI;AACF,UAAM,OAAO,KAAK,MAAM,KAAK,cAAe,SAAU;AACtD,aAAS,WAAW,KAAI,UAAK,SAAS,MAAd,mBAAiB,KAAK;AAC9C,UAAM,SAAS,KAAK,QAAQ,EAAE,KAAK;AACnC,aAAS,QAAQ,IAAI;AACrB,QAAI,aAAa,MAAM,MAAM,QAAW;AACtC,cAAQ,aAAa,MAAM;AAAA,IAC7B,OAAO;AACL,YAAM,IAAI,MAAM,wBAAwB,MAAM,EAAE;AAAA,IAClD;AAAA,EACF,SAAS,GAAY;AACnB,YAAQ;AACR,YAAQ,GAAG,CAAC;AAAA,EACd;AAEA,SAAO;AAAA,IACL;AAAA,IACA;AAAA,IACA;AAAA,EACF;AACF;AAQO,SAAS,0BAAsC;AAAA,EACpD;AAAA,EACA;AAAA,EACA;AAAA,EACA,QAAQ;AAAA,EACR,QAAQ;AAAA,EACR;AACF,GAOkD;AAChD,QAAM,gBAAgB,OAAO,KAAK,YAAY;AAC9C,QAAM,MAAM,OACV,gBACG;AAvNP;AAwNI,UAAM,UAAS,uBAAY,WAAZ,YAAsB,cAAtB,YAAmC;AAElD,UAAM,SACJ,iBAAiB,QAAQ,SAAS,aAAa;AAEjD,QAAI,YAAY;AAChB,UAAM,WAAoC;AAAA,MACxC;AAAA,QACE,MAAM;AAAA,QACN,SAAS;AAAA,MACX;AAAA,IACF;AAEA,WAAO,MAAM,iBAAiB;AAAA,MAC5B;AAAA,MACA;AAAA,MACA;AAAA,MACA,yBAAyB,6BAA6B,MAAM;AAAA,MAC5D;AAAA,MACA;AAAA,MACA;AAAA,MACA,WAAW;AAAA,OACR,cATyB;AAAA;AAAA;AAAA,MAa5B;AAAA,IACF,EAAC;AAAA,EACH;AACA,SAAO,eAAe,KAAK,QAAQ;AAAA,IACjC,OAAO;AAAA,IACP,cAAc;AAAA,EAChB,CAAC;AAED,SAAO;AACT;AAUO,SAAS,sBACd,MACA,MAC4C;AAC5C,SAAO,0BAA0B;AAAA,IAC/B;AAAA,IACA,gBAAgB,KAAK;AAAA,IACrB,cAAc,KAAK;AAAA,IACnB,OAAO,KAAK;AAAA,IACZ,QAAQ,KAAK;AAAA,IACb,aAAa,KAAK;AAAA,EACpB,CAAC;AACH;AAEO,SAAS,0BACd,MACA,cAC4C;AAC5C,QAAM,MAAW,UAAK,UAAU,YAAY,CAAC;AAC7C,SAAO,sBAAsB,MAAM,GAAG;AACxC;AAEA,SAAS,mBACP,MACA,cACA;AACA,MAAI,EAAE,gBAAgB,YAAY;AAChC,UAAM,IAAI,MAAM,kBAAkB,IAAI,YAAY;AAAA,EACpD;AAEA,SAAO;AAAA,IACL;AAAA,IACA;AAAA,EACF;AACF;AAMO,IAAM,SAAS;AAAA,EACpB;AAAA,EACA;AACF;AAMO,IAAM,WAAW;AAAA,EACtB;AAAA,EACA;AACF;AAKO,IAAM,QAAQ,mBAAuB,SAAS,OAAO;AAKrD,IAAM,aAAa,mBAIvB,cAAc,YAAY;AAKtB,IAAM,WAAW;AAAA,EACtB;AAAA,EACA;AACF;AAKO,IAAM,WAAW,mBAAuB,YAAY,UAAU;AAK9D,IAAM,MAAM,mBAAsC,OAAO,KAAK;AAK9D,IAAM,UAAU;AAAA,EACrB;AAAA,EACA;AACF;AAMO,IAAM,cAAc,mBAGxB,eAAe,aAAa;;;AazW/B,OAAO,iBAAiB;AAKjB,IAAM,oBAAwC,CAAC,SAAS;AAC7D,MAAI,KAAK,aAAa,QAAW;AAC/B,UAAM,IAAI,MAAM,8CAA8C;AAAA,EAChE;AAEA,QAAM,CAAC,QAAQ,QAAQ,IAAI,CAAC,GAAG,KAAK,MAAM,IAAI,GAAG,KAAK,QAAQ,EAAE;AAChE,QAAM,SAAS,KAAK,IAAI,OAAO,QAAQ,SAAS,MAAM;AAEtD,MAAI,QAAQ;AACZ,MAAI,SAAS,GAAG;AACd,YAAQ,IAAI,YAAY,QAAQ,QAAQ,IAAI;AAAA,EAC9C;AAEA,SAAO;AAAA,IACL,MAAM;AAAA,IACN;AAAA,EACF;AACF;;;AClBO,IAAM,cAAkC,CAAC,SAAS;AACvD,QAAM,EAAE,QAAQ,SAAS,IAAI;AAE7B,MAAI,aAAa,QAAW;AAC1B,UAAM,IAAI,MAAM,8CAA8C;AAAA,EAChE;AAEA,QAAM,QACJ,WAAW,KAAK,aAAa,IACzB,IACA,IACA,KAAK,IAAI,WAAW,MAAM,KAAK,KAAK,IAAI,QAAQ,IAAI,KAAK,IAAI,MAAM;AAEzE,SAAO;AAAA,IACL,MAAM;AAAA,IACN;AAAA,EACF;AACF;;;ACdO,IAAM,WAGT,OAAO;AAAA,EACT;AAAA,EACA;AAAA,EACA,eAAe;AAAA,EACf,eAAe;AACjB,MAAM;AACJ,SAAO;AAAA,IACL,MAAM;AAAA,IACN,OAAO,MAAM,SAAS,QAAQ,UAAU,cAAc,YAAY;AAAA,EACpE;AACF;AAEA,eAAe,SACb,IACA,IACA,cACA,cACiB;AACjB,MAAI,SAAS,EAAE,KAAK,SAAS,EAAE,GAAG;AAChC,QAAI,OAAO,KAAK,EAAE,EAAE,UAAU,KAAK,OAAO,KAAK,EAAE,EAAE,UAAU,GAAG;AAC9D,aAAO;AAAA,IACT;AAEA,UAAM,UAAU,OAAO;AAAA,MACrB,OAAO;AAAA,QACL,OAAO,KAAK,EAAE,EACX,OAAO,OAAO,KAAK,EAAE,CAAC,EACtB,IAAI,CAAC,MAAM,CAAC,GAAG,IAAI,CAAC;AAAA,MACzB;AAAA,IACF;AAEA,UAAM,aAAa,MAAM,QAAQ;AAAA,MAC/B,QAAQ,IAAI,CAAC,MAAM,SAAS,GAAG,CAAC,GAAG,GAAG,CAAC,GAAG,cAAc,YAAY,CAAC;AAAA,IACvE;AACA,WAAO,WAAW,OAAO,CAAC,KAAK,MAAM,MAAM,GAAG,CAAC,IAAI,WAAW;AAAA,EAChE,WAAW,QAAQ,EAAE,KAAK,QAAQ,EAAE,GAAG;AACrC,QAAI,GAAG,WAAW,KAAK,GAAG,WAAW,GAAG;AACtC,aAAO;AAAA,IACT;AAEA,UAAM,aAAa,MAAM,QAAQ;AAAA,MAC/B,MAAM,KAAK;AAAA,QACT,QAAQ,KAAK,IAAI,GAAG,QAAQ,GAAG,MAAM;AAAA,MACvC,CAAC,EAAE,IAAI,CAAC,GAAG,MAAM,SAAS,GAAG,CAAC,GAAG,GAAG,CAAC,GAAG,cAAc,YAAY,CAAC;AAAA,IACrE;AACA,WACE,WAAW,OAAO,CAAC,KAAK,MAAM,MAAM,GAAG,CAAC,IAAI,KAAK,IAAI,GAAG,QAAQ,GAAG,MAAM;AAAA,EAE7E,WAAW,OAAO,OAAO,YAAY,OAAO,OAAO,UAAU;AAC3D,YAAQ,MAAM,aAAa,EAAE,QAAQ,IAAI,UAAU,GAAG,CAAC,GAAG;AAAA,EAC5D,WAAW,OAAO,OAAO,YAAY,OAAO,OAAO,UAAU;AAC3D,YAAQ,MAAM,aAAa,EAAE,QAAQ,IAAI,UAAU,GAAG,CAAC,GAAG;AAAA,EAC5D,YACG,OAAO,QAAQ,OAAO,YACtB,OAAO,QAAQ,OAAO,SACvB;AACA,WAAO;AAAA,EACT,WACE,OAAO,QACP,OAAO,UACP,OAAO,QACP,OAAO,QACP;AACA,WAAO;AAAA,EACT,OAAO;AACL,YACE,MAAM,aAAa;AAAA,MACjB,QAAQ,KAAK,UAAU,IAAI,QAAQ;AAAA,MACnC,UAAU,KAAK,UAAU,IAAI,QAAQ;AAAA,IACvC,CAAC,GACD;AAAA,EACJ;AACF;AAEA,SAAS,SAAS,OAA6C;AAC7D,SAAO,iBAAiB,UAAU,EAAE,iBAAiB;AACvD;AAEA,SAAS,QAAQ,OAAqC;AACpD,SAAO,iBAAiB;AAC1B;AAGA,IAAM,WAAW,CAAC,KAAa,UAC7B,SAAS,KAAK,IACV,OAAO,KAAK,KAAK,EACd,KAAK,EACL,OAAO,CAAC,QAAgCA,SAAQ;AAC/C,SAAOA,IAAG,IAAI,MAAMA,IAAG;AACvB,SAAO;AACT,GAAG,CAAC,CAAC,IACP;;;ACrGN,IAAI,iBAAiB,QAAQ,IAAI;",
  "names": ["key"]
}
